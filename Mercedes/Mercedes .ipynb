{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercedes competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mercedes and Sberbank were my two first non training kaggle competitions. Unfortunately, I started to do them several days before deadline, therefore my results aren't very expressive. Nevertheless, it gave a good understanding of what data could be for these competitions.\n",
    "\n",
    "Mercedes competition consists of prediction of necessary test time for mercedes automobiles using car's technical caracteristics and other car's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 377) (4209, 376)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         y  X0 X1  X2 X3 X4 X5 X6 X8  X10  ...   X375  X376  X377  X378  X379  \\\n",
       "ID                                         ...                                  \n",
       "0   130.81   k  v  at  a  d  u  j  o    0  ...      0     0     1     0     0   \n",
       "6    88.53   k  t  av  e  d  y  l  o    0  ...      1     0     0     0     0   \n",
       "7    76.26  az  w   n  c  d  x  j  x    0  ...      0     0     0     0     0   \n",
       "9    80.62  az  t   n  f  d  x  l  e    0  ...      0     0     0     0     0   \n",
       "13   78.02  az  v   n  f  d  h  d  n    0  ...      0     0     0     0     0   \n",
       "\n",
       "    X380  X382  X383  X384  X385  \n",
       "ID                                \n",
       "0      0     0     0     0     0  \n",
       "6      0     0     0     0     0  \n",
       "7      0     1     0     0     0  \n",
       "9      0     0     0     0     0  \n",
       "13     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset\n",
    "df_train = pd.read_csv('train.csv', header = 0, index_col = 0)\n",
    "df_test = pd.read_csv('test.csv', header = 0, index_col = 0)\n",
    "y_train = df_train['y']\n",
    "print(df_train.shape, df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see here two particular features of this data set:\n",
    "\n",
    "* data is anonymous, we don't know either names of the features, or categories of categorical features\n",
    "* all features are either categorical (first eight features) or binary\n",
    "\n",
    "So here we have to predict continous feature using only discrete features. Morevover we see, that 12 features in train dataset are constant features, so we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y       2545\n",
       "X0        47\n",
       "X2        44\n",
       "X5        29\n",
       "X1        27\n",
       "X8        25\n",
       "X6        12\n",
       "X3         7\n",
       "X4         4\n",
       "X137       2\n",
       "X128       2\n",
       "X129       2\n",
       "X130       2\n",
       "X131       2\n",
       "X132       2\n",
       "X133       2\n",
       "X134       2\n",
       "X135       2\n",
       "X136       2\n",
       "X141       2\n",
       "X138       2\n",
       "X139       2\n",
       "X140       2\n",
       "X126       2\n",
       "X142       2\n",
       "X143       2\n",
       "X144       2\n",
       "X145       2\n",
       "X146       2\n",
       "X127       2\n",
       "        ... \n",
       "X265       2\n",
       "X267       2\n",
       "X263       2\n",
       "X255       2\n",
       "X248       2\n",
       "X249       2\n",
       "X250       2\n",
       "X251       2\n",
       "X252       2\n",
       "X253       2\n",
       "X262       2\n",
       "X254       2\n",
       "X256       2\n",
       "X261       2\n",
       "X257       2\n",
       "X258       2\n",
       "X259       2\n",
       "X260       2\n",
       "X233       1\n",
       "X93        1\n",
       "X289       1\n",
       "X330       1\n",
       "X293       1\n",
       "X107       1\n",
       "X268       1\n",
       "X347       1\n",
       "X297       1\n",
       "X11        1\n",
       "X235       1\n",
       "X290       1\n",
       "Name: unique, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exploring categories\n",
    "cat_sorted = df_train.astype('object').describe().iloc[1,:].sort_values(ascending = False)\n",
    "cat_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing constant features\n",
    "to_drop = list(cat_sorted[cat_sorted == 1].index)\n",
    "df_train.drop(to_drop, axis = 1, inplace = True)\n",
    "df_test.drop(to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selecting binary features\n",
    "df_train_cat = df_train.iloc[:,1:9]\n",
    "df_test_cat = df_test.iloc[:,:8]\n",
    "X_train_bin = df_train.iloc[:,9:].values\n",
    "X_test_bin = df_test.iloc[:,8:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, there are 8 categorical features and others are binary. So we will use three strategies to deal with categorical features and choose the best one:\n",
    "\n",
    "* we will transform categorical features into dummy variables (so we'll have only binary features in our data set)\n",
    "* we will give a numerical value for every category\n",
    "* we will use frequency of every category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#categorical features\n",
    "df_all = pd.concat([df_train_cat, df_test_cat])\n",
    "df_dummies = pd.get_dummies(df_all)\n",
    "X_train_dummies = df_dummies.iloc[:len(df_train),:].values\n",
    "X_test_dummies = df_dummies.iloc[len(df_train):,:].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "for feature in df_all.columns:\n",
    "    df_all[feature] = le.fit_transform(df_all[feature].values)\n",
    "    df_train_cat[feature] = df_train_cat[feature].map(df_train_cat.groupby(feature).size()) / len(df_train_cat)\n",
    "    df_test_cat[feature] = df_test_cat[feature].map(df_test_cat.groupby(feature).size()) / len(df_test_cat)\n",
    "X_train_le = df_all.iloc[:len(df_train),:]\n",
    "X_test_le = df_all.iloc[len(df_train):,:]\n",
    "X_train_freq = df_train_cat.values\n",
    "X_test_freq = df_test_cat.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we create three data sets, if we work with all features as binary, we have 567 features instead of 364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 567) (4209, 364) (4209, 364)\n"
     ]
    }
   ],
   "source": [
    "# train test sets\n",
    "X_train_dummies = np.concatenate((X_train_dummies, X_train_bin), axis = 1)\n",
    "X_test_dummies = np.concatenate((X_test_dummies, X_test_bin), axis = 1)\n",
    "\n",
    "X_train_le = np.concatenate((X_train_le, X_train_bin), axis = 1)\n",
    "X_test_le = np.concatenate((X_test_le, X_test_bin), axis = 1)\n",
    "\n",
    "X_train_freq = np.concatenate((X_train_freq, X_train_bin), axis = 1)\n",
    "X_test_freq = np.concatenate((X_test_freq, X_test_bin), axis = 1)\n",
    "print(X_train_dummies.shape, X_train_le.shape, X_train_freq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could suppose, linear regression is useless here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.90199190359e+23 -3.62084835444e+18 -3.292542421e+20\n"
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "linreg = LinearRegression()\n",
    "kf = KFold(n_splits = 4, shuffle = True, random_state = 147)\n",
    "r2_dummies = np.mean(cross_val_score(linreg, X_train_dummies, y_train, cv = kf, scoring = 'r2'))\n",
    "r2_le = np.mean(cross_val_score(linreg, X_train_le, y_train, cv = kf, scoring = 'r2'))\n",
    "r2_freq = np.mean(cross_val_score(linreg, X_train_freq, y_train, cv = kf, scoring = 'r2'))\n",
    "print(r2_dummies, r2_le, r2_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest works much better with only categorical and binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500385123258 0.493534157463 0.482674752432\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "rf_reg = RandomForestRegressor(n_estimators = 100, random_state = 147)\n",
    "r2_dummies = np.mean(cross_val_score(rf_reg, X_train_dummies, y_train, cv = kf, scoring = 'r2'))\n",
    "r2_le = np.mean(cross_val_score(rf_reg, X_train_le, y_train, cv = kf, scoring = 'r2'))\n",
    "r2_freq = np.mean(cross_val_score(rf_reg, X_train_freq, y_train, cv = kf, scoring = 'r2'))\n",
    "print(r2_dummies, r2_le, r2_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting works even better. Mind you, that for random forest dummy variables were the mosr efficient strategy, for gradient boosting category frequency shows the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553578660386 0.561805064686 0.5670388735\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting\n",
    "gb_reg = GradientBoostingRegressor(n_estimators = 100, random_state = 147)\n",
    "r2_dummies = np.mean(cross_val_score(gb_reg, X_train_dummies, y_train, cv = kf, scoring = 'r2'))\n",
    "r2_le = np.mean(cross_val_score(gb_reg, X_train_le, y_train, cv = kf, scoring = 'r2'))\n",
    "r2_freq = np.mean(cross_val_score(gb_reg, X_train_freq, y_train, cv = kf, scoring = 'r2'))\n",
    "print(r2_dummies, r2_le, r2_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform feature selection to make model's performance better and to reduce time for training. As we see, feature selection helps us to improve model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 84) (4209, 79) 0.509206738668 0.571004474253\n"
     ]
    }
   ],
   "source": [
    "# model selection\n",
    "rf_reg.fit(X_train_dummies, y_train)\n",
    "rf_dummies_model = SelectFromModel(rf_reg, prefit = True)\n",
    "X_train_dummies_rf = rf_dummies_model.transform(X_train_dummies)\n",
    "X_test_dummies_rf = rf_dummies_model.transform(X_test_dummies)\n",
    "\n",
    "gb_reg.fit(X_train_freq, y_train)\n",
    "gb_freq_model = SelectFromModel(gb_reg, prefit = True)\n",
    "X_train_freq_gb = gb_freq_model.transform(X_train_freq)\n",
    "X_test_freq_gb = gb_freq_model.transform(X_test_freq)\n",
    "\n",
    "r2_rf_model = np.mean(cross_val_score(rf_reg, X_train_dummies_rf, y_train, cv = kf, scoring = 'r2'))\n",
    "r2_gb_model = np.mean(cross_val_score(gb_reg, X_train_freq_gb, y_train, cv = kf, scoring = 'r2'))\n",
    "print(X_train_dummies_rf.shape, X_train_freq_gb.shape, r2_rf_model, r2_gb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters tuning by grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.539962237452 {'n_estimators': 1500, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "grid_rf = {'n_estimators': [1250, 1500, 1750], 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "gs_rf = GridSearchCV(rf_reg, grid_rf, cv = kf, scoring = 'r2')\n",
    "gs_rf.fit(X_train_dummies_rf, y_train)\n",
    "print(gs_rf.best_score_, gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.577027638703 {'max_depth': 2, 'learning_rate': 0.075, 'n_estimators': 175}\n"
     ]
    }
   ],
   "source": [
    "grid_gb = {'n_estimators': [165, 170, 175, 180, 185], 'learning_rate': [0.065, 0.07, 0.075, 0.08, 0.085], \n",
    "           'max_depth': [2, 3, 4]}\n",
    "gs_gb = GridSearchCV(gb_reg, grid_gb, cv = kf, scoring = 'r2')\n",
    "gs_gb.fit(X_train_freq_gb, y_train)\n",
    "print(gs_gb.best_score_, gs_gb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_test['y'] = gs_rf.predict(X_test_dummies_rf)\n",
    "#df_test['y'] = gs_gb.predict(X_test_freq_gb)\n",
    "df_test['y'] = gs_rf.predict(X_test_dummies_rf) / 2 + gs_gb.predict(X_test_freq_gb) / 2\n",
    "df_test[['y']].to_csv('prediction.csv', sep = ',', header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Best public score: 0.55454, best private score: 0.54532. In this case 0.2 of data was used for public score and 0.8 for private, therefore difference in performance is huge. For example, top 3 in public leaderbord have lost about 1500 places in private. I have lost about 700 places."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
